+++
title = "common-sense morality"
author = ["Pablo Stafforini"]
date = 2020-08-31
tags = ["article", "biblio", "public"]
draft = false
work = "bostrom-2016-infinite-ethics"
locator = "p. 40"
+++
> Suppose we were convinced that the (by far) most likely scenario involving infinite values goes something like follows: One day our descendants discover some new physics which lets them develop a technology that makes it possible to create an infinite number of people in what otherwise would have been a finite cosmos. If our current behavior has some probabilistic effect, however slim, on how our descendants will act, we would then (according to EDR) have a reason to act in such a way as to maximize the probability that we will have descendants who will develop such infinite powers and use them for good ends. It is not obvious which courses of action would have this property. But it seems plausible that they would fall within the range acceptable to common sense morality. For instance, it seems more likely that ending world hunger would increase, and that gratuitous genocide would decrease, the probability that the human species will survive to develop infinitely powerful technologies and use them for good rather than evil ends, than that the opposite should be true. More generally, working towards a morally decent society, as traditionally understood, would appear to be a good way to promote the eventual technological realization of infinite goods.
